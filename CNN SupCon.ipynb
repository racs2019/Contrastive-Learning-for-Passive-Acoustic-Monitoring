{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6290c28-3c78-420f-9552-a0da062b2d4f",
   "metadata": {},
   "source": [
    "Dependencies\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c919930-21a6-4ee2-b61b-8655a755a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supcon_audio.py  — updated\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchaudio\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    adjusted_mutual_info_score,\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from torchvision.models import resnet18\n",
    "from typing import Optional, Dict, Any, Sequence, Tuple\n",
    "\n",
    "# Safe UMAP import (avoid AttributeError: module 'umap' has no attribute 'UMAP')\n",
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e2ece-f2be-4b01-90d8-487ce182d773",
   "metadata": {},
   "source": [
    "Training\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1486686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:07:38.030198Z",
     "iopub.status.busy": "2025-08-28T18:07:38.029954Z",
     "iopub.status.idle": "2025-08-28T18:07:38.070794Z",
     "shell.execute_reply": "2025-08-28T18:07:38.070131Z",
     "shell.execute_reply.started": "2025-08-28T18:07:38.030179Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Dataset with Dual Views\n",
    "# ----------------------------\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, audio_dir, label_path, sr=10000, n_mels=64, augment_fn=None):\n",
    "        self.audio_paths = sorted(\n",
    "            [os.path.join(audio_dir, f) for f in os.listdir(audio_dir)\n",
    "             if f.endswith(\".npy\") and f != \"labels.npy\"],\n",
    "            key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
    "        )\n",
    "        self.labels = np.load(label_path)\n",
    "        assert len(self.audio_paths) == len(self.labels), \"Mismatch: number of audio files and labels\"\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.augment_fn = augment_fn\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sr, n_fft=1024, hop_length=512, n_mels=n_mels\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y = np.load(self.audio_paths[idx]).astype(np.float32)\n",
    "        y = y / (np.max(np.abs(y)) + 1e-8)\n",
    "        y_tensor = torch.tensor(y).unsqueeze(0)\n",
    "        mel = self.mel_transform(y_tensor)\n",
    "        logmel = torch.log(mel + 1e-8)\n",
    "        x1 = self.augment_fn(logmel.clone()) if self.augment_fn else logmel\n",
    "        x2 = self.augment_fn(logmel.clone()) if self.augment_fn else logmel\n",
    "        return x1, x2, int(self.labels[idx])\n",
    "\n",
    "# ----------------------------\n",
    "# Encoder with ResNet18\n",
    "# ----------------------------\n",
    "class ConvSupConEncoder(nn.Module):\n",
    "    def __init__(self, output_dim=64):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(pretrained=False)\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.projector(x)\n",
    "        return F.normalize(x, dim=1)\n",
    "\n",
    "# ----------------------------\n",
    "# SupCon Loss\n",
    "# ----------------------------\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.03):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0]\n",
    "        labels = labels.view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        contrast = torch.div(torch.matmul(features, features.T), self.temperature)\n",
    "        logits_max, _ = torch.max(contrast, dim=1, keepdim=True)\n",
    "        logits = contrast - logits_max.detach()\n",
    "        logits_mask = torch.ones_like(mask) - torch.eye(batch_size).to(device)\n",
    "        mask *= logits_mask\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n",
    "        return -mean_log_prob_pos.mean()\n",
    "\n",
    "# ----------------------------\n",
    "# Eval helpers\n",
    "# ----------------------------\n",
    "def hungarian_accuracy(y_true, y_pred):\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(len(y_pred)):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    return sum(w[i, j] for i, j in zip(row_ind, col_ind)) / len(y_pred)\n",
    "\n",
    "def _internal_indices(X: np.ndarray, labels: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Silhouette / DB / CH with guards.\"\"\"\n",
    "    out = {\"silhouette\": float(\"nan\"),\n",
    "           \"davies_bouldin\": float(\"nan\"),\n",
    "           \"calinski_harabasz\": float(\"nan\")}\n",
    "    uniq = np.unique(labels)\n",
    "    if len(uniq) <= 1 or len(uniq) >= len(labels):\n",
    "        return out\n",
    "    try:\n",
    "        out[\"silhouette\"] = float(silhouette_score(X, labels))\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        out[\"davies_bouldin\"] = float(davies_bouldin_score(X, labels))\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        out[\"calinski_harabasz\"] = float(calinski_harabasz_score(X, labels))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return out\n",
    "\n",
    "def _kmeans_metrics(emb: np.ndarray, y_true: np.ndarray, kmeans_k: Optional[int] = None, random_state: int = 42) -> Dict[str, float]:\n",
    "    n_clusters = int(kmeans_k) if kmeans_k is not None else len(np.unique(y_true))\n",
    "    preds = KMeans(n_clusters=n_clusters, n_init=10, random_state=random_state).fit_predict(emb)\n",
    "    ari = adjusted_rand_score(y_true, preds)\n",
    "    ami = adjusted_mutual_info_score(y_true, preds)\n",
    "    h_acc = hungarian_accuracy(y_true, preds)\n",
    "    extra = _internal_indices(emb, preds)\n",
    "    return {\n",
    "        \"ari\": float(ari),\n",
    "        \"ami\": float(ami),\n",
    "        \"hungarian_accuracy\": float(h_acc),\n",
    "        \"silhouette\": float(extra[\"silhouette\"]),\n",
    "        \"davies_bouldin\": float(extra[\"davies_bouldin\"]),\n",
    "        \"calinski_harabasz\": float(extra[\"calinski_harabasz\"]),\n",
    "        \"kmeans_k\": int(n_clusters),\n",
    "    }\n",
    "\n",
    "def evaluate_embeddings(encoder, loader, device, *, kmeans_k: Optional[int] = None, random_state: int = 42):\n",
    "    \"\"\"Returns KMeans metrics on embeddings from `loader`.\"\"\"\n",
    "    encoder.eval()\n",
    "    all_embeddings, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, _, labels in loader:\n",
    "            x = x.to(device)\n",
    "            emb = encoder(x).cpu().numpy()\n",
    "            all_embeddings.append(emb)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.array(all_labels)\n",
    "    return _kmeans_metrics(all_embeddings, all_labels, kmeans_k=kmeans_k, random_state=random_state)\n",
    "\n",
    "# ----------------------------\n",
    "# SpecAugment\n",
    "# ----------------------------\n",
    "def augment_audio(x):\n",
    "    if x.dim() == 3:\n",
    "        # [1, F, T]\n",
    "        mask_freq = x.clone()\n",
    "        mask_time = x.clone()\n",
    "        F_dim, T_dim = mask_freq.size(1), mask_freq.size(2)\n",
    "        freq_mask = max(1, int(0.2 * F_dim))\n",
    "        freq_start = torch.randint(0, max(1, F_dim - freq_mask), (1,))\n",
    "        mask_freq[:, freq_start:freq_start+freq_mask, :] = 0\n",
    "        time_mask = max(1, int(0.2 * T_dim))\n",
    "        time_start = torch.randint(0, max(1, T_dim - time_mask), (1,))\n",
    "        mask_time[:, :, time_start:time_start+time_mask] = 0\n",
    "        return mask_freq + mask_time\n",
    "    elif x.dim() == 4:\n",
    "        # [B, 1, F, T]\n",
    "        mask_freq = x.clone()\n",
    "        mask_time = x.clone()\n",
    "        F_dim, T_dim = mask_freq.size(2), mask_freq.size(3)\n",
    "        freq_mask = max(1, int(0.2 * F_dim))\n",
    "        freq_start = torch.randint(0, max(1, F_dim - freq_mask), (1,))\n",
    "        mask_freq[:, :, freq_start:freq_start+freq_mask, :] = 0\n",
    "        time_mask = max(1, int(0.2 * T_dim))\n",
    "        time_start = torch.randint(0, max(1, T_dim - time_mask), (1,))\n",
    "        mask_time[:, :, :, time_start:time_start+time_mask] = 0\n",
    "        return mask_freq + mask_time\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected input shape: {x.shape}\")\n",
    "\n",
    "# ======================================================\n",
    "# Split helper — do the stratified 80/20 split OUTSIDE training\n",
    "# ======================================================\n",
    "def make_fixed_train_test_indices(dataset_path: str, *, test_size: float = 0.2, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Return stratified indices (train_idx, test_idx) in the same order used by SpectrogramDataset.\"\"\"\n",
    "    audio_paths = sorted(\n",
    "        [os.path.join(dataset_path, f) for f in os.listdir(dataset_path)\n",
    "         if f.endswith(\".npy\") and f != \"labels.npy\"],\n",
    "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
    "    )\n",
    "    labels = np.load(os.path.join(dataset_path, \"labels.npy\"))\n",
    "    assert len(audio_paths) == len(labels), \"Mismatch between files and labels\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    indices = np.arange(len(audio_paths))\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        indices, test_size=test_size, stratify=labels, random_state=random_state\n",
    "    )\n",
    "    return np.asarray(train_idx), np.asarray(test_idx)\n",
    "\n",
    "# ======================================================\n",
    "# Runner 1: TRAINING (uses ONLY provided train indices)\n",
    "# ======================================================\n",
    "def run_training(\n",
    "    dataset_path: str,\n",
    "    *,\n",
    "    train_indices: Sequence[int],          # REQUIRED: indices from make_fixed_train_test_indices (80%)\n",
    "    val_split: float = 0.1,                # taken from the 80% train portion\n",
    "    batch_size: int = 256,\n",
    "    num_workers: int = 4,\n",
    "    epochs: int = 30,\n",
    "    lr: float = 2e-3,\n",
    "    weight_decay: float = 1e-4,\n",
    "    temperature: float = 0.03,\n",
    "    eval_every: int = 10,\n",
    "    patience: int = 50,\n",
    "    checkpoint_in: Optional[str] = \"best_encoder_pretrain.pth\",\n",
    "    checkpoint_out: str = \"best_encoder_pretrain.pth\",\n",
    "    seed: int = 42,\n",
    "    val_kmeans_k: Optional[int] = None,    # optional: fix k during periodic validation\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Pretrains encoder with SupCon on dual-views spectrograms.\n",
    "    Periodically evaluates with KMeans on a VALIDATION split carved from the provided TRAIN indices.\n",
    "    The held-out TEST set is NOT touched here (created outside; pass to run_inference).\n",
    "    \"\"\"\n",
    "    # Repro\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    audio_dir = dataset_path\n",
    "    label_path = os.path.join(audio_dir, \"labels.npy\")\n",
    "    if not os.path.isdir(audio_dir):\n",
    "        raise FileNotFoundError(f\"Dataset directory not found: {audio_dir}\")\n",
    "    if not os.path.isfile(label_path):\n",
    "        raise FileNotFoundError(f\"Label file not found: {label_path}\")\n",
    "\n",
    "    # Base dataset; restrict to TRAIN indices only\n",
    "    full_dataset = SpectrogramDataset(audio_dir, label_path, augment_fn=augment_audio)\n",
    "    train_base = Subset(full_dataset, list(train_indices))\n",
    "\n",
    "    # Carve a validation split from the train_base\n",
    "    val_size = max(1, int(round(val_split * len(train_base))))\n",
    "    train_size = len(train_base) - val_size\n",
    "    if train_size <= 0:\n",
    "        raise ValueError(f\"val_split too large for train size {len(train_base)}\")\n",
    "\n",
    "    train_dataset, val_dataset = random_split(train_base, [train_size, val_size], generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "        drop_last=True, pin_memory=True, persistent_workers=num_workers > 0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "        drop_last=False, pin_memory=True, persistent_workers=num_workers > 0\n",
    "    )\n",
    "\n",
    "    # Model/optim\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder = ConvSupConEncoder().to(device)\n",
    "    criterion = SupConLoss(temperature=temperature)\n",
    "    optimizer = torch.optim.Adam(encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Optional warm-start\n",
    "    if checkpoint_in and os.path.isfile(checkpoint_in):\n",
    "        try:\n",
    "            encoder.load_state_dict(torch.load(checkpoint_in, map_location=device))\n",
    "            print(f\"Loaded checkpoint from {checkpoint_in}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: failed to load checkpoint '{checkpoint_in}': {e}\")\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if device.type == \"cuda\" else None\n",
    "\n",
    "    best_hungarian, no_improve_epochs = 0.0, 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        encoder.train()\n",
    "        total_loss = 0.0\n",
    "        for x1, x2, labels in train_loader:\n",
    "            x1, x2, labels = x1.to(device, non_blocking=True), x2.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scaler:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    z1 = encoder(x1); z2 = encoder(x2)\n",
    "                    features = torch.cat([z1, z2], dim=0)\n",
    "                    labels_dual = torch.cat([labels, labels], dim=0)\n",
    "                    loss = criterion(features, labels_dual)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                z1 = encoder(x1); z2 = encoder(x2)\n",
    "                features = torch.cat([z1, z2], dim=0)\n",
    "                labels_dual = torch.cat([labels, labels], dim=0)\n",
    "                loss = criterion(features, labels_dual)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"[Pretrain] Epoch {epoch}/{epochs}  Train Loss: {total_loss:.4f}\")\n",
    "\n",
    "        # Periodic eval on VAL (not test)\n",
    "        if epoch % eval_every == 0:\n",
    "            val_metrics = evaluate_embeddings(encoder, val_loader, device, kmeans_k=val_kmeans_k, random_state=seed)\n",
    "            print(f\"[Pretrain] Validation — \"\n",
    "                  f\"ARI: {val_metrics['ari']:.4f}, AMI: {val_metrics['ami']:.4f}, \"\n",
    "                  f\"Hungarian: {val_metrics['hungarian_accuracy']:.4f}\")\n",
    "\n",
    "            if val_metrics[\"hungarian_accuracy\"] > best_hungarian:\n",
    "                best_hungarian = val_metrics[\"hungarian_accuracy\"]\n",
    "                no_improve_epochs = 0\n",
    "                torch.save(encoder.state_dict(), checkpoint_out)\n",
    "                print(f\"✅ Epoch {epoch} — New best saved to '{checkpoint_out}' (Hungarian: {best_hungarian:.4f})\")\n",
    "            else:\n",
    "                no_improve_epochs += eval_every\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"⏹️ Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "    if not os.path.isfile(checkpoint_out):\n",
    "        torch.save(encoder.state_dict(), checkpoint_out)\n",
    "        print(f\"Saved final model to '{checkpoint_out}'\")\n",
    "\n",
    "    return {\n",
    "        \"best_hungarian\": float(best_hungarian),\n",
    "        \"checkpoint_out\": checkpoint_out,\n",
    "        \"epochs_run\": epoch,\n",
    "        \"train_samples\": len(train_dataset),\n",
    "        \"val_samples\": len(val_dataset),\n",
    "        \"device\": str(device),\n",
    "    }\n",
    "\n",
    "# ======================================================\n",
    "# Runner 2: INFERENCE / EVAL / UMAP  (uses ONLY provided test indices)\n",
    "# ======================================================\n",
    "def run_inference(\n",
    "    dataset_path: str,\n",
    "    *,\n",
    "    test_indices: Sequence[int],           # REQUIRED: the same 20% held out\n",
    "    checkpoint_path: str = \"best_encoder_pretrain.pth\",\n",
    "    batch_size: int = 384,\n",
    "    num_workers: int = 4,\n",
    "    do_clustering: bool = True,\n",
    "    kmeans_k: Optional[int] = None,        # choose k (else infer from y_test)\n",
    "    do_umap: bool = True,\n",
    "    umap_components: int = 3,\n",
    "    umap_html_path: str = \"umap_embeddings.html\",\n",
    "    seed: int = 42,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Loads encoder, extracts embeddings on the FIXED TEST subset (the provided 20%),\n",
    "    computes KMeans metrics (ARI/AMI/H-Acc + Silhouette/DB/CH), and optionally saves UMAP HTML.\n",
    "    \"\"\"\n",
    "    # Repro\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    audio_dir = dataset_path\n",
    "    label_path = os.path.join(audio_dir, \"labels.npy\")\n",
    "    if not os.path.isdir(audio_dir):\n",
    "        raise FileNotFoundError(f\"Dataset directory not found: {audio_dir}\")\n",
    "    if not os.path.isfile(label_path):\n",
    "        raise FileNotFoundError(f\"Label file not found: {label_path}\")\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "\n",
    "    full_dataset = SpectrogramDataset(audio_dir, label_path, augment_fn=None)\n",
    "    test_subset = Subset(full_dataset, list(test_indices))\n",
    "    loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder = ConvSupConEncoder().to(device)\n",
    "    encoder.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    encoder.eval()\n",
    "\n",
    "    # Extract embeddings for TEST subset\n",
    "    all_embeddings, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x1, _, labels in loader:\n",
    "            x1 = x1.to(device, non_blocking=True)\n",
    "            emb = encoder(x1).cpu().numpy()\n",
    "            all_embeddings.append(emb)\n",
    "            all_labels.append(labels.numpy())\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    results: Dict[str, Any] = {\n",
    "        \"embeddings_shape\": tuple(all_embeddings.shape),\n",
    "        \"labels_shape\": tuple(all_labels.shape),\n",
    "        \"checkpoint\": checkpoint_path\n",
    "    }\n",
    "\n",
    "    # Clustering metrics on TEST embeddings\n",
    "    if do_clustering:\n",
    "        metrics = _kmeans_metrics(all_embeddings, all_labels, kmeans_k=kmeans_k, random_state=seed)\n",
    "        print(f\"[Test] KMeans (k={metrics['kmeans_k']}) — \"\n",
    "              f\"ARI: {metrics['ari']:.4f}, AMI: {metrics['ami']:.4f}, \"\n",
    "              f\"Hungarian: {metrics['hungarian_accuracy']:.4f}\")\n",
    "        print(f\"[Test] Silhouette: {metrics['silhouette']:.4f} | \"\n",
    "              f\"Davies–Bouldin: {metrics['davies_bouldin']:.4f} | \"\n",
    "              f\"Calinski–Harabasz: {metrics['calinski_harabasz']:.2f}\")\n",
    "        results[\"metrics\"] = metrics\n",
    "\n",
    "    # Optional UMAP on TEST embeddings\n",
    "    if do_umap:\n",
    "        reducer = umap.UMAP(n_components=umap_components, random_state=seed)\n",
    "        emb_umap = reducer.fit_transform(all_embeddings)\n",
    "        if umap_components == 3:\n",
    "            fig = plotly_3d(emb_umap, all_labels, title=\"3D UMAP of TEST Embeddings\")\n",
    "        elif umap_components == 2:\n",
    "            fig = plotly_2d(emb_umap, all_labels, title=\"2D UMAP of TEST Embeddings\")\n",
    "        else:\n",
    "            raise ValueError(\"umap_components must be 2 or 3\")\n",
    "        fig.write_html(umap_html_path)\n",
    "        print(f\"Saved UMAP visualization to '{umap_html_path}'\")\n",
    "        results[\"umap_html_path\"] = umap_html_path\n",
    "\n",
    "    return results\n",
    "\n",
    "# Small helpers for plotting\n",
    "def plotly_3d(emb, labels, title=\"3D UMAP\"):\n",
    "    import plotly.express as px\n",
    "    fig = px.scatter_3d(\n",
    "        x=emb[:,0], y=emb[:,1], z=emb[:,2],\n",
    "        color=labels.astype(str),\n",
    "        title=title,\n",
    "        labels={\"x\":\"UMAP-1\",\"y\":\"UMAP-2\",\"z\":\"UMAP-3\"},\n",
    "        opacity=0.7\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=3))\n",
    "    fig.update_layout(legend_title_text='True Label', width=800, height=700)\n",
    "    return fig\n",
    "\n",
    "def plotly_2d(emb, labels, title=\"2D UMAP\"):\n",
    "    import plotly.express as px\n",
    "    fig = px.scatter(\n",
    "        x=emb[:,0], y=emb[:,1],\n",
    "        color=labels.astype(str),\n",
    "        title=title,\n",
    "        labels={\"x\":\"UMAP-1\",\"y\":\"UMAP-2\"},\n",
    "        opacity=0.7\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=4))\n",
    "    fig.update_layout(legend_title_text='True Label', width=800, height=650)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f8182-903c-4e42-bfbe-eef0ccd0dd8d",
   "metadata": {},
   "source": [
    "Train/test runner with metrics\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "650abd02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T18:08:32.198127Z",
     "iopub.status.busy": "2025-08-28T18:08:32.197590Z",
     "iopub.status.idle": "2025-08-28T18:13:43.913784Z",
     "shell.execute_reply": "2025-08-28T18:13:43.913136Z",
     "shell.execute_reply.started": "2025-08-28T18:08:32.198108Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning:\n",
      "\n",
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning:\n",
      "\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] KMeans (k=6) — ARI: 0.3715, AMI: 0.3956, Hungarian: 0.6456\n",
      "[Test] Silhouette: 0.4459 | Davies–Bouldin: 1.0093 | Calinski–Harabasz: 70264.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved UMAP visualization to 'SupCon_k6.html'\n",
      "{'ari': 0.3715453842629094, 'ami': 0.39558826152268695, 'hungarian_accuracy': 0.6455628818583268, 'silhouette': 0.44588062167167664, 'davies_bouldin': 1.0093408090839737, 'calinski_harabasz': 70264.93860863186, 'kmeans_k': 6}\n"
     ]
    }
   ],
   "source": [
    "# # 1) Create the fixed split ONCE (outside training)\n",
    "train_idx, test_idx = make_fixed_train_test_indices(\"/notebooks/dataset_preprocessed\", test_size=0.2, random_state=42)\n",
    "\n",
    "# # 2) Train ONLY on the 80% (we carve a small val from that 80%)\n",
    "# train_res = run_training(\n",
    "#     dataset_path=\"/notebooks/dataset_preprocessed\",\n",
    "#     train_indices=train_idx,\n",
    "#     epochs=30,\n",
    "#     eval_every=10,\n",
    "#     checkpoint_out=\"CNNbest_encoder_pretrain.pth\",\n",
    "#     val_kmeans_k=60,     # optional during val\n",
    "# )\n",
    "\n",
    "# 3) Evaluate ONLY on the held-out 20% (same indices)\n",
    "test_res = run_inference(\n",
    "    dataset_path=\"/notebooks/dataset_preprocessed\",\n",
    "    test_indices=test_idx,       # <- the exact same 20%\n",
    "    checkpoint_path=\"best_encoder_pretrain.pth\",\n",
    "    do_clustering=True,\n",
    "    kmeans_k=6,                 # choose k; else inferred from y_test\n",
    "    do_umap=True,\n",
    "    umap_components=3,\n",
    "    umap_html_path=\"SupCon_k6.html\",\n",
    ")\n",
    "\n",
    "print(test_res.get(\"metrics\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e5f55-9427-4a4d-8b1e-49408a6822fd",
   "metadata": {},
   "source": [
    "Extended Reports\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54655f6-1e00-4fef-a748-52e62eff8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SUPCON REPORT (SimCLR-style) =====\n",
    "# Add this block to the end of supcon_audio.py (after your existing code)\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# safe UMAP import (works if you already did `import umap.umap_ as umap` earlier)\n",
    "try:\n",
    "    import umap.umap_ as umap\n",
    "except Exception:\n",
    "    import umap  # type: ignore\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import spectrogram, get_window\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# ---------- File utilities ----------\n",
    "def _list_audio_npy_files(folder: str) -> List[str]:\n",
    "    files = []\n",
    "    for f in os.listdir(folder):\n",
    "        if f.endswith(\".npy\") and f != \"labels.npy\":\n",
    "            stem = os.path.splitext(f)[0]\n",
    "            try:\n",
    "                key = int(stem)\n",
    "            except ValueError:\n",
    "                key = stem\n",
    "            files.append((key, os.path.join(folder, f)))\n",
    "    files.sort(key=lambda t: t[0])\n",
    "    return [p for _, p in files]\n",
    "\n",
    "\n",
    "def _load_class_labels_if_any(folder: str, count: int) -> np.ndarray:\n",
    "    lbl_path = os.path.join(folder, \"labels.npy\")\n",
    "    if os.path.isfile(lbl_path):\n",
    "        try:\n",
    "            arr = np.load(lbl_path, allow_pickle=True)\n",
    "            if len(arr) < count:\n",
    "                pad = np.array([\"Unknown\"] * (count - len(arr)), dtype=object)\n",
    "                arr = np.concatenate([arr, pad], axis=0)\n",
    "            elif len(arr) > count:\n",
    "                arr = arr[:count]\n",
    "            return arr\n",
    "        except Exception:\n",
    "            pass\n",
    "    return np.array([\"Unknown\"] * count, dtype=object)\n",
    "\n",
    "\n",
    "# ---------- Spectrogram thumbnail helpers ----------\n",
    "def _ali_spec(x: np.ndarray, fs: int = 10000):\n",
    "    Lframe2 = 1000\n",
    "    po = 80\n",
    "    lov = int(np.ceil((po / 100) * Lframe2))\n",
    "    taper = get_window(\"hann\", Lframe2)\n",
    "    Nfft = 2 ** (int(np.floor(np.log2(Lframe2))) + 2)\n",
    "    f, t, s = spectrogram(\n",
    "        x, fs=fs, window=taper, noverlap=lov, nfft=Nfft, mode=\"complex\"\n",
    "    )\n",
    "    as_ = np.abs(s)\n",
    "    as_max = np.max(as_) if np.isfinite(np.max(as_)) and np.max(as_) > 0 else 1.0\n",
    "    sdb = 10 * np.log10(100 * as_ / as_max + 1e-10)\n",
    "    min_inx = np.argmin(np.abs(f - 0))\n",
    "    max_inx = np.argmin(np.abs(f - 800))\n",
    "    return sdb[min_inx : max_inx + 1, :], f[min_inx : max_inx + 1], t\n",
    "\n",
    "\n",
    "def _spec_img_base64(\n",
    "    audio_or_spec: np.ndarray, title: str, fs: int = 10000\n",
    ") -> str:\n",
    "    if audio_or_spec.ndim == 1:\n",
    "        spec, f_axis, t_axis = _ali_spec(audio_or_spec.astype(np.float32), fs)\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        ax.imshow(\n",
    "            spec,\n",
    "            aspect=\"auto\",\n",
    "            origin=\"lower\",\n",
    "            extent=[t_axis[0], t_axis[-1], f_axis[0], f_axis[-1]],\n",
    "            cmap=\"hsv\",\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Hz\")\n",
    "    else:\n",
    "        S = audio_or_spec.squeeze()\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        ax.imshow(S, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Frames\")\n",
    "        ax.set_ylabel(\"Mel bins\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=120)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    image_base64 = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    return (\n",
    "        f'<img class=\"d-block w-100\" src=\"data:image/png;base64,{image_base64}\" '\n",
    "        f'alt=\"{title}\">'\n",
    "    )\n",
    "\n",
    "\n",
    "def _carousel_html(cluster_id: int, scope: str, imgs: List[str]) -> str:\n",
    "    cid = f\"carousel_{scope}_{cluster_id}\"\n",
    "    indicators = \"\".join(\n",
    "        f'<button type=\"button\" data-bs-target=\"#{cid}\" data-bs-slide-to=\"{i}\" '\n",
    "        f'{\"class=active\" if i==0 else \"\"} aria-current=\"true\" '\n",
    "        f'aria-label=\"Slide {i+1}\"></button>'\n",
    "        for i in range(len(imgs))\n",
    "    )\n",
    "    items = \"\".join(\n",
    "        f'<div class=\"carousel-item {\"active\" if i==0 else \"\"}\">'\n",
    "        f'<div class=\"d-flex justify-content-center\">{img}</div>'\n",
    "        f\"</div>\"\n",
    "        for i, img in enumerate(imgs)\n",
    "    )\n",
    "    return f\"\"\"\n",
    "    <div id=\"{cid}\" class=\"carousel slide\" data-bs-interval=\"false\" data-bs-touch=\"false\">\n",
    "      <div class=\"carousel-indicators\">{indicators}</div>\n",
    "      <div class=\"carousel-inner\">{items}</div>\n",
    "      <button class=\"carousel-control-prev\" type=\"button\" data-bs-target=\"#{cid}\" data-bs-slide=\"prev\">\n",
    "        <span class=\"carousel-control-prev-icon\" aria-hidden=\"true\"></span>\n",
    "        <span class=\"visually-hidden\">Previous</span>\n",
    "      </button>\n",
    "      <button class=\"carousel-control-next\" type=\"button\" data-bs-target=\"#{cid}\" data-bs-slide=\"next\">\n",
    "        <span class=\"carousel-control-next-icon\" aria-hidden=\"true\"></span>\n",
    "        <span class=\"visually-hidden\">Next</span>\n",
    "      </button>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# ---------- Per-cluster metrics (same as SimCLR report) ----------\n",
    "def _evaluate_cluster_metrics(\n",
    "    embeddings: np.ndarray,\n",
    "    idxs: np.ndarray,\n",
    "    location_labels: np.ndarray,\n",
    "    location_entropy_base: Optional[int] = None,\n",
    ") -> Dict[str, float]:\n",
    "    X = embeddings[idxs]\n",
    "    if X.shape[0] == 0:\n",
    "        return {\n",
    "            \"variance\": 0.0,\n",
    "            \"mean_sim\": 1.0,\n",
    "            \"entropy\": 0.0,\n",
    "            \"quality\": 0.0,\n",
    "            \"novelty\": 0.0,\n",
    "        }\n",
    "    center = np.mean(X, axis=0, keepdims=True)\n",
    "    variance = float(np.mean(np.sum((X - center) ** 2, axis=1)))\n",
    "    if len(X) > 1:\n",
    "        cos_sim = cosine_similarity(X)\n",
    "        iu = np.triu_indices_from(cos_sim, k=1)\n",
    "        mean_sim = float(np.mean(cos_sim[iu])) if iu[0].size > 0 else 1.0\n",
    "    else:\n",
    "        mean_sim = 1.0\n",
    "    loc_counts = Counter(location_labels[idxs])\n",
    "    loc_probs = np.array(list(loc_counts.values()), dtype=np.float32)\n",
    "    loc_probs /= max(loc_probs.sum(), 1e-8)\n",
    "    base = int(location_entropy_base or len(set(location_labels)))\n",
    "    loc_entropy = float(entropy(loc_probs, base=base)) if base > 1 else 0.0\n",
    "    max_ent = np.log2(base) if base > 1 else 1.0\n",
    "    entropy_score = 1.0 - (loc_entropy / max_ent) if base > 1 else 1.0\n",
    "    quality = float((mean_sim / (variance + 1e-8)) * entropy_score)\n",
    "    novelty = float((loc_entropy / max_ent) * variance) if base > 1 else 0.0\n",
    "    return {\n",
    "        \"variance\": variance,\n",
    "        \"mean_sim\": mean_sim,\n",
    "        \"entropy\": loc_entropy,\n",
    "        \"quality\": quality,\n",
    "        \"novelty\": novelty,\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- Embed a subset with your SupCon encoder ----------\n",
    "def _load_supcon_encoder(checkpoint_path: str, device: torch.device):\n",
    "    enc = ConvSupConEncoder().to(device)  # uses your class defined earlier\n",
    "    sd = torch.load(checkpoint_path, map_location=device)\n",
    "    if isinstance(sd, dict) and \"state_dict\" in sd:\n",
    "        sd = sd[\"state_dict\"]\n",
    "    enc.load_state_dict(sd, strict=False)\n",
    "    enc.eval()\n",
    "    print(f\"[INFO] SupCon encoder loaded from {checkpoint_path} on {device}\")\n",
    "    return enc\n",
    "\n",
    "\n",
    "def _extract_embeds_from_dir(\n",
    "    dataset_path: str,\n",
    "    location_tag: str,\n",
    "    checkpoint_path: str,\n",
    "    *,\n",
    "    subset_fraction: float = 0.02,\n",
    "    subset_seed: int = 42,\n",
    "    batch_size: int = 256,\n",
    "    num_workers: int = 0,\n",
    "):\n",
    "    all_files = _list_audio_npy_files(dataset_path)\n",
    "    if len(all_files) == 0:\n",
    "        raise RuntimeError(f\"No .npy files found in {dataset_path}\")\n",
    "\n",
    "    n_sub = max(1, int(math.ceil(len(all_files) * subset_fraction)))\n",
    "    rng = np.random.RandomState(subset_seed)\n",
    "    chosen_idx = np.sort(rng.choice(len(all_files), size=n_sub, replace=False))\n",
    "    chosen_files = [all_files[i] for i in chosen_idx]\n",
    "\n",
    "    # dataset & subset aligned to SpectrogramDataset's ordering\n",
    "    ds = SpectrogramDataset(\n",
    "        dataset_path, os.path.join(dataset_path, \"labels.npy\"), augment_fn=None\n",
    "    )\n",
    "    subset = Subset(ds, chosen_idx.tolist())\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    enc = _load_supcon_encoder(checkpoint_path, device)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    feats, cls_labels = [], []\n",
    "    t0 = time.perf_counter()\n",
    "    seen = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (x1, _, y) in enumerate(loader):\n",
    "            x1 = x1.to(device, non_blocking=True)\n",
    "            h = enc(x1).cpu().numpy().astype(\"float32\")\n",
    "            feats.append(h)\n",
    "            cls_labels.append(y.numpy())\n",
    "            seen += x1.size(0)\n",
    "            if (step + 1) % 10 == 0 or step == 0:\n",
    "                dt = time.perf_counter() - t0\n",
    "                print(f\"[Embed] {seen}/{n_sub} • {seen / max(dt, 1e-9):.1f} it/s\")\n",
    "\n",
    "    H = np.vstack(feats).astype(\"float32\")\n",
    "    cls = np.concatenate(cls_labels, axis=0)\n",
    "    loc = np.array([location_tag] * H.shape[0], dtype=object)\n",
    "    print(f\"[INFO] {dataset_path} → {H.shape} embeds\")\n",
    "    return H, cls, loc, np.array(chosen_files, dtype=object)\n",
    "\n",
    "\n",
    "# ---------- Main analysis to HTML ----------\n",
    "def analyze_supcon_to_html(\n",
    "    checkpoint_path: str,\n",
    "    dataset_paths: List[str],\n",
    "    location_tags: List[str],\n",
    "    *,\n",
    "    cluster_method: str = \"kmeans\",  # 'kmeans' | 'gmm' | 'agglomerative'\n",
    "    n_clusters: int = 60,\n",
    "    subset_fraction: float = 0.02,\n",
    "    subset_seed: int = 42,\n",
    "    samples_per_cluster: int = 4,\n",
    "    top_n_clusters: Optional[int] = None,  # rank by size; None = show all\n",
    ") -> str:\n",
    "    assert len(dataset_paths) == len(location_tags), (\n",
    "        \"dataset_paths and location_tags must match\"\n",
    "    )\n",
    "\n",
    "    # Collect embeddings from each location\n",
    "    embeds_all, class_all, loc_all, files_all = [], [], [], []\n",
    "    for path, tag in zip(dataset_paths, location_tags):\n",
    "        H, cls, loc, files = _extract_embeds_from_dir(\n",
    "            path, tag, checkpoint_path,\n",
    "            subset_fraction=subset_fraction,\n",
    "            subset_seed=subset_seed,\n",
    "        )\n",
    "        embeds_all.append(H)\n",
    "        class_all.append(cls)\n",
    "        loc_all.append(loc)\n",
    "        files_all.append(files)\n",
    "\n",
    "    embeddings = np.vstack(embeds_all).astype(\"float32\")\n",
    "    class_labels = np.concatenate(class_all, axis=0).astype(object)\n",
    "    location_labels = np.concatenate(loc_all, axis=0).astype(object)\n",
    "    original_paths = np.concatenate(files_all, axis=0).astype(object)\n",
    "\n",
    "    # UMAP (cosine) on embeddings\n",
    "    print(f\"[INFO] UMAP on {embeddings.shape[0]}×{embeddings.shape[1]}\")\n",
    "    reducer = umap.UMAP(\n",
    "        n_components=3, n_neighbors=15, min_dist=0.1, metric=\"cosine\", random_state=42\n",
    "    )\n",
    "    proj_3d = reducer.fit_transform(embeddings)\n",
    "\n",
    "    # Clustering\n",
    "    def _choose_clusterer(algorithm: str, X: np.ndarray, k: int):\n",
    "        if algorithm == \"kmeans\":\n",
    "            model = KMeans(n_clusters=k, n_init=\"auto\", random_state=42).fit(X)\n",
    "            return model.labels_, None\n",
    "        elif algorithm == \"agglomerative\":\n",
    "            from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "            model = AgglomerativeClustering(n_clusters=k).fit(X)\n",
    "            return model.labels_, None\n",
    "        elif algorithm == \"gmm\":\n",
    "            from sklearn.mixture import GaussianMixture\n",
    "\n",
    "            model = GaussianMixture(\n",
    "                n_components=k, covariance_type=\"full\", random_state=42\n",
    "            ).fit(X)\n",
    "            return model.predict(X), model.predict_proba(X)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported algorithm: {algorithm}\")\n",
    "\n",
    "    print(f\"[INFO] Clustering with {cluster_method} (k={n_clusters})\")\n",
    "    cluster_labels, _ = _choose_clusterer(cluster_method, embeddings, n_clusters)\n",
    "\n",
    "    # Global metrics (same as SimCLR report) on embeddings, not UMAP\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    valid = (len(unique_clusters) > 1) and (embeddings.shape[0] > len(unique_clusters))\n",
    "\n",
    "    def _safe_metric(fn, X, y):\n",
    "        try:\n",
    "            return float(fn(X, y)) if valid else float(\"nan\")\n",
    "        except Exception:\n",
    "            return float(\"nan\")\n",
    "\n",
    "    sil = _safe_metric(silhouette_score, embeddings, cluster_labels)\n",
    "    dbi = _safe_metric(davies_bouldin_score, embeddings, cluster_labels)\n",
    "    ch = _safe_metric(calinski_harabasz_score, embeddings, cluster_labels)\n",
    "\n",
    "    title_txt = f\"{cluster_method.capitalize()} (Sil={sil:.3f} | DBI={dbi:.3f} | CH={ch:.1f})\"\n",
    "    fig = px.scatter_3d(\n",
    "        x=proj_3d[:, 0],\n",
    "        y=proj_3d[:, 1],\n",
    "        z=proj_3d[:, 2],\n",
    "        color=[str(c) for c in cluster_labels],\n",
    "        symbol=location_labels,\n",
    "        hover_data={\"Cluster\": cluster_labels, \"Class\": class_labels},\n",
    "        title=title_txt,\n",
    "        opacity=0.85,\n",
    "        height=800,\n",
    "    )\n",
    "    umap_html = pio.to_html(fig, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "    # Per-cluster sections\n",
    "    base_for_entropy = len(set(location_labels))\n",
    "    cluster_ids = sorted(\n",
    "        set(cluster_labels),\n",
    "        key=lambda c: np.sum(cluster_labels == c),\n",
    "        reverse=True,\n",
    "    )\n",
    "    if top_n_clusters is not None:\n",
    "        cluster_ids = cluster_ids[: int(top_n_clusters)]\n",
    "\n",
    "    blocks = []\n",
    "    for cid in cluster_ids:\n",
    "        idxs = np.where(cluster_labels == cid)[0]\n",
    "        if idxs.size == 0:\n",
    "            continue\n",
    "\n",
    "        sz = len(idxs)\n",
    "        loc_counts = Counter(location_labels[idxs])\n",
    "        cls_counts = Counter(class_labels[idxs])\n",
    "        metrics = _evaluate_cluster_metrics(\n",
    "            embeddings, idxs, location_labels, location_entropy_base=base_for_entropy\n",
    "        )\n",
    "\n",
    "        meta_html = (\n",
    "            \"<p><strong>Location Distribution:</strong></p><ul>\"\n",
    "            + \"\".join(\n",
    "                f\"<li><b>{loc}</b>: {count} ({count/sz:.1%})</li>\"\n",
    "                for loc, count in loc_counts.items()\n",
    "            )\n",
    "            + \"</ul>\"\n",
    "        )\n",
    "        meta_html += (\n",
    "            \"<p><strong>Class Distribution:</strong></p><ul>\"\n",
    "            + \"\".join(f\"<li>{cls}: {count}</li>\" for cls, count in cls_counts.items())\n",
    "            + \"</ul>\"\n",
    "        )\n",
    "        meta_html += f\"\"\"\n",
    "        <p><strong>Cluster Metrics:</strong></p>\n",
    "        <ul>\n",
    "          <li>Size: {sz}</li>\n",
    "          <li>Intra-Cluster Variance: {metrics['variance']:.4f}</li>\n",
    "          <li>Mean Cosine Similarity: {metrics['mean_sim']:.4f}</li>\n",
    "          <li>Location Entropy: {metrics['entropy']:.3f}</li>\n",
    "          <li>Composite Quality Score: {metrics['quality']:.4f}</li>\n",
    "          <li><strong>Novelty Score:</strong> {metrics['novelty']:.4f}</li>\n",
    "        </ul>\n",
    "        \"\"\"\n",
    "\n",
    "        # nearest to center exemplars\n",
    "        center = np.mean(embeddings[idxs], axis=0, keepdims=True)\n",
    "        dists = np.linalg.norm(embeddings[idxs] - center, axis=1)\n",
    "        order = np.argsort(dists)\n",
    "        pick = idxs[order[: min(samples_per_cluster, len(order))]]\n",
    "\n",
    "        thumbs = []\n",
    "        for i, p in enumerate(pick):\n",
    "            try:\n",
    "                arr = np.load(original_paths[p], mmap_mode=\"r\")\n",
    "                title = f\"#{i+1} | {location_labels[p]} | Class {class_labels[p]}\"\n",
    "                thumbs.append(_spec_img_base64(arr, title))\n",
    "            except Exception as e:\n",
    "                thumbs.append(f\"<p class='text-danger'>Error: {e}</p>\")\n",
    "\n",
    "        blocks.append(\n",
    "            f\"<div class='col-md-6 mb-4'><h4>Cluster {cid}</h4>\"\n",
    "            f\"{meta_html}{_carousel_html(cid, 'supcon', thumbs)}</div>\"\n",
    "        )\n",
    "\n",
    "    cluster_html = \"\"\n",
    "    for i in range(0, len(blocks), 2):\n",
    "        cluster_html += \"<div class='row'>\" + \"\".join(blocks[i : i + 2]) + \"</div>\"\n",
    "\n",
    "    return f\"\"\"\n",
    "    <div class='section'>\n",
    "      <h2>{cluster_method.capitalize()} Clustering Analysis (SupCon • subset {int(subset_fraction*100)}%)</h2>\n",
    "      <div class=\"container\">\n",
    "        <div class=\"row justify-content-center mb-4\">\n",
    "          <div class=\"col-md-12 d-flex justify-content-center\">{umap_html}</div>\n",
    "        </div>\n",
    "      </div>\n",
    "      {cluster_html}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# ---------- Full HTML wrapper ----------\n",
    "def generate_supcon_full_report(\n",
    "    checkpoint_path: str,\n",
    "    dataset_paths: List[str],\n",
    "    location_tags: List[str],\n",
    "    *,\n",
    "    out_html: str = \"supcon_unsupervised_report.html\",\n",
    "    cluster_method: str = \"kmeans\",\n",
    "    n_clusters: int = 60,\n",
    "    subset_fraction: float = 0.02,\n",
    "    subset_seed: int = 42,\n",
    "    samples_per_cluster: int = 4,\n",
    "    top_n_clusters: Optional[int] = None,\n",
    ") -> str:\n",
    "    section = analyze_supcon_to_html(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        dataset_paths=list(dataset_paths),\n",
    "        location_tags=list(location_tags),\n",
    "        cluster_method=cluster_method,\n",
    "        n_clusters=int(n_clusters),\n",
    "        subset_fraction=subset_fraction,\n",
    "        subset_seed=subset_seed,\n",
    "        samples_per_cluster=samples_per_cluster,\n",
    "        top_n_clusters=top_n_clusters,\n",
    "    )\n",
    "    html = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Unsupervised Clustering Report (SupCon)</title>\n",
    "        <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"></script>\n",
    "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; padding: 20px; background-color: #f5f5f5; }}\n",
    "            h1 {{ color: #2c3e50; }}\n",
    "            h2, h4 {{ color: #34495e; }}\n",
    "            hr {{ border-top: 2px solid #bbb; margin-top: 40px; margin-bottom: 40px; }}\n",
    "            .section {{ margin-bottom: 60px; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "      <h1 class='mb-4'>Unsupervised Latent Clustering Report (SupCon)</h1>\n",
    "      <p><strong>Locations:</strong> {', '.join(location_tags)}</p>\n",
    "      <p><strong>Subset:</strong> {int(subset_fraction*100)}% • Seed: {subset_seed}</p>\n",
    "      <hr>\n",
    "      {section}\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    with open(out_html, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(f\"✅ Report saved to: {out_html}\")\n",
    "    return out_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b085146-6a1e-45ab-ac88-798f64f8f0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T17:41:21.385035Z",
     "iopub.status.busy": "2025-08-28T17:41:21.384797Z",
     "iopub.status.idle": "2025-08-28T18:03:28.487836Z",
     "shell.execute_reply": "2025-08-28T18:03:28.486904Z",
     "shell.execute_reply.started": "2025-08-28T17:41:21.385025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SupCon encoder loaded from best_encoder_pretrain.pth on cuda\n",
      "[Embed] 256/82655 • 202.0 it/s\n",
      "[Embed] 2560/82655 • 140.9 it/s\n",
      "[Embed] 5120/82655 • 117.4 it/s\n",
      "[Embed] 7680/82655 • 95.7 it/s\n",
      "[Embed] 10240/82655 • 86.5 it/s\n",
      "[Embed] 12800/82655 • 80.1 it/s\n",
      "[Embed] 15360/82655 • 81.8 it/s\n",
      "[Embed] 17920/82655 • 79.9 it/s\n",
      "[Embed] 20480/82655 • 72.5 it/s\n",
      "[Embed] 23040/82655 • 72.7 it/s\n",
      "[Embed] 25600/82655 • 73.8 it/s\n",
      "[Embed] 28160/82655 • 75.0 it/s\n",
      "[Embed] 30720/82655 • 73.5 it/s\n",
      "[Embed] 33280/82655 • 74.4 it/s\n",
      "[Embed] 35840/82655 • 75.1 it/s\n",
      "[Embed] 38400/82655 • 72.4 it/s\n",
      "[Embed] 40960/82655 • 72.1 it/s\n",
      "[Embed] 43520/82655 • 72.1 it/s\n",
      "[Embed] 46080/82655 • 72.1 it/s\n",
      "[Embed] 48640/82655 • 73.0 it/s\n",
      "[Embed] 51200/82655 • 73.4 it/s\n",
      "[Embed] 53760/82655 • 74.5 it/s\n",
      "[Embed] 56320/82655 • 75.3 it/s\n",
      "[Embed] 58880/82655 • 75.6 it/s\n",
      "[Embed] 61440/82655 • 74.9 it/s\n",
      "[Embed] 64000/82655 • 75.4 it/s\n",
      "[Embed] 66560/82655 • 75.0 it/s\n",
      "[Embed] 69120/82655 • 74.8 it/s\n",
      "[Embed] 71680/82655 • 75.0 it/s\n",
      "[Embed] 74240/82655 • 75.1 it/s\n",
      "[Embed] 76800/82655 • 73.9 it/s\n",
      "[Embed] 79360/82655 • 74.1 it/s\n",
      "[Embed] 81920/82655 • 72.9 it/s\n",
      "[INFO] /notebooks/dataset_preprocessed → (82655, 64) embeds\n",
      "[INFO] UMAP on 82655×64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Clustering with kmeans (k=60)\n",
      "✅ Report saved to: SupCon_unsupervised_clustering_report.html\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Unsupervised Latent Clustering Report for SupCon (and compatible encoders)\n",
    "\n",
    "Generates an HTML report including:\n",
    "- UMAP visualization of embeddings (color by cluster, symbol by location)\n",
    "- Global clustering metrics (Silhouette, DBI, CH)\n",
    "- Per-cluster metrics (variance, mean cosine, entropy, quality, novelty)\n",
    "- Spectrogram-space consistency metrics:\n",
    "    * Mean spectrogram cosine similarity (↑ better)\n",
    "    * Mean DTW distance on time courses (↓ better; optional via fastdtw)\n",
    "\n",
    "Usage (example):\n",
    "    python supcon_full_report.py \\\n",
    "        --checkpoint /path/to/supcon_encoder.ckpt \\\n",
    "        --dataset /data/siteA /data/siteB \\\n",
    "        --tags SiteA SiteB \\\n",
    "        --out supcon_unsupervised_report.html \\\n",
    "        --cluster gmm --k 60 --subset 0.02 --seed 42 \\\n",
    "        --samples-per-cluster 4 --top-n 40\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "# ----- Core libs -----\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # headless\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# ML / metrics\n",
    "import umap\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import spectrogram, get_window\n",
    "\n",
    "# ----- Project-specific imports (edit paths/names if needed) -----\n",
    "# Expect these to be available in your codebase:\n",
    "# - ConvSupConEncoder: your SupCon-compatible encoder\n",
    "# - SpectrogramDataset: returns spectrograms / waveforms + labels\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# File helpers\n",
    "# ============================================================\n",
    "\n",
    "def _list_audio_npy_files(folder: str) -> List[str]:\n",
    "    files = []\n",
    "    for f in os.listdir(folder):\n",
    "        if f.endswith(\".npy\") and f != \"labels.npy\":\n",
    "            stem = os.path.splitext(f)[0]\n",
    "            try:\n",
    "                key = int(stem)\n",
    "            except ValueError:\n",
    "                key = stem\n",
    "            files.append((key, os.path.join(folder, f)))\n",
    "    files.sort(key=lambda t: t[0])\n",
    "    return [p for _, p in files]\n",
    "\n",
    "\n",
    "def _load_class_labels_if_any(folder: str, count: int) -> np.ndarray:\n",
    "    lbl_path = os.path.join(folder, \"labels.npy\")\n",
    "    if os.path.isfile(lbl_path):\n",
    "        try:\n",
    "            arr = np.load(lbl_path, allow_pickle=True)\n",
    "            if len(arr) < count:\n",
    "                pad = np.array([\"Unknown\"] * (count - len(arr)), dtype=object)\n",
    "                arr = np.concatenate([arr, pad], axis=0)\n",
    "            elif len(arr) > count:\n",
    "                arr = arr[:count]\n",
    "            return arr\n",
    "        except Exception:\n",
    "            pass\n",
    "    return np.array([\"Unknown\"] * count, dtype=object)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Spectrogram helpers\n",
    "# ============================================================\n",
    "\n",
    "def _ali_spec(x: np.ndarray, fs: int = 10000) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Make a Hann-windowed spectrogram (complex), then log-like scale, 0–800Hz band.\"\"\"\n",
    "    Lframe2 = 1000\n",
    "    po = 80\n",
    "    lov = int(math.ceil((po / 100) * Lframe2))\n",
    "    taper = get_window('hann', Lframe2)\n",
    "    Nfft = 2 ** (int(math.floor(math.log2(Lframe2))) + 2)\n",
    "    f, t, s = spectrogram(x, fs=fs, window=taper, noverlap=lov, nfft=Nfft, mode='complex')\n",
    "    as_ = np.abs(s)\n",
    "    as_max = np.max(as_) if np.isfinite(np.max(as_)) and np.max(as_) > 0 else 1.0\n",
    "    sdb = 10 * np.log10(100 * as_ / as_max + 1e-10)\n",
    "    min_inx = np.argmin(np.abs(f - 0))\n",
    "    max_inx = np.argmin(np.abs(f - 800))\n",
    "    return sdb[min_inx:max_inx+1, :], f[min_inx:max_inx+1], t\n",
    "\n",
    "\n",
    "def _spec_img_base64(audio_or_spec: np.ndarray, title: str, fs: int = 10000) -> str:\n",
    "    if audio_or_spec.ndim == 1:\n",
    "        spec, f_axis, t_axis = _ali_spec(audio_or_spec.astype(np.float32), fs)\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        im = ax.imshow(spec, aspect='auto', origin='lower',\n",
    "                       extent=[t_axis[0], t_axis[-1], f_axis[0], f_axis[-1]])\n",
    "        ax.set_title(title); ax.set_xlabel(\"Time (s)\"); ax.set_ylabel(\"Hz\")\n",
    "    else:\n",
    "        S = audio_or_spec.squeeze()\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        im = ax.imshow(S, aspect='auto', origin='lower')\n",
    "        ax.set_title(title); ax.set_xlabel(\"Frames\"); ax.set_ylabel(\"Bins\")\n",
    "    fig.tight_layout()\n",
    "    buf = BytesIO(); fig.savefig(buf, format='png', dpi=120); plt.close(fig); buf.seek(0)\n",
    "    image_base64 = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    return f'<img class=\"d-block w-100\" src=\"data:image/png;base64,{image_base64}\" alt=\"{title}\">'\n",
    "\n",
    "\n",
    "def _standardize_spec(S: np.ndarray, target_shape=(128, 256)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pad/crop 2D (F,T) spectrogram to target_shape. Per-spec z-norm for cosine comparability.\n",
    "    \"\"\"\n",
    "    S = np.asarray(S, dtype=np.float32)\n",
    "    S = (S - np.mean(S)) / (np.std(S) + 1e-8)\n",
    "    F, T = S.shape\n",
    "    Ft, Tt = target_shape\n",
    "\n",
    "    # F dimension\n",
    "    if F < Ft:\n",
    "        pad_top = (Ft - F) // 2\n",
    "        pad_bot = Ft - F - pad_top\n",
    "        S = np.pad(S, ((pad_top, pad_bot), (0, 0)), mode=\"constant\")\n",
    "    elif F > Ft:\n",
    "        start = (F - Ft) // 2\n",
    "        S = S[start:start+Ft, :]\n",
    "\n",
    "    # T dimension\n",
    "    F, T = S.shape\n",
    "    if T < Tt:\n",
    "        pad_left = (Tt - T) // 2\n",
    "        pad_right = Tt - T - pad_left\n",
    "        S = np.pad(S, ((0, 0), (pad_left, pad_right)), mode=\"constant\")\n",
    "    elif T > Tt:\n",
    "        start = (T - Tt) // 2\n",
    "        S = S[:, start:start+Tt]\n",
    "    return S\n",
    "\n",
    "\n",
    "def _load_spec_for_index(original_paths: np.ndarray, idx: int, fs: int = 10000,\n",
    "                         target_shape=(128, 256)) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load .npy (1D waveform or 2D spectrogram) and return standardized 2D spectrogram.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        arr = np.load(original_paths[idx], mmap_mode=\"r\")\n",
    "        if arr.ndim == 1:\n",
    "            S, _, _ = _ali_spec(arr.astype(np.float32), fs=fs)\n",
    "        elif arr.ndim == 2:\n",
    "            S = arr.astype(np.float32)\n",
    "        else:\n",
    "            return None\n",
    "        return _standardize_spec(S, target_shape=target_shape)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _avg_intra_cluster_spec_cosine(original_paths: np.ndarray, idxs: np.ndarray,\n",
    "                                   *, fs: int = 10000, max_samples: int = 50,\n",
    "                                   target_shape=(128, 256)) -> float:\n",
    "    \"\"\"\n",
    "    Average pairwise cosine similarity of standardized spectrograms within a cluster.\n",
    "    Subsamples up to max_samples items for O(n^2) stability.\n",
    "    \"\"\"\n",
    "    if len(idxs) < 2:\n",
    "        return float(\"nan\")\n",
    "    if len(idxs) > max_samples:\n",
    "        rng = np.random.RandomState(42)\n",
    "        idxs = rng.choice(idxs, size=max_samples, replace=False)\n",
    "\n",
    "    specs = []\n",
    "    for i in idxs:\n",
    "        S = _load_spec_for_index(original_paths, int(i), fs=fs, target_shape=target_shape)\n",
    "        if S is not None:\n",
    "            specs.append(S.reshape(-1))\n",
    "    if len(specs) < 2:\n",
    "        return float(\"nan\")\n",
    "    X = np.stack(specs, axis=0)\n",
    "    sim = cosine_similarity(X)\n",
    "    iu = np.triu_indices_from(sim, k=1)\n",
    "    return float(np.mean(sim[iu]))\n",
    "\n",
    "\n",
    "def _avg_intra_cluster_spec_dtw(original_paths: np.ndarray, idxs: np.ndarray,\n",
    "                                *, fs: int = 10000, max_samples: int = 25,\n",
    "                                target_shape=(128, 256)) -> float:\n",
    "    \"\"\"\n",
    "    Average pairwise DTW distance between standardized spectrogram time-traces.\n",
    "    Lower = more similar. Optional: requires fastdtw.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from fastdtw import fastdtw\n",
    "        from scipy.spatial.distance import euclidean\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if len(idxs) < 2:\n",
    "        return float(\"nan\")\n",
    "    if len(idxs) > max_samples:\n",
    "        rng = np.random.RandomState(42)\n",
    "        idxs = rng.choice(idxs, size=max_samples, replace=False)\n",
    "\n",
    "    series = []\n",
    "    for i in idxs:\n",
    "        S = _load_spec_for_index(original_paths, int(i), fs=fs, target_shape=target_shape)\n",
    "        if S is not None:\n",
    "            series.append(np.mean(S, axis=0))  # collapse freq\n",
    "    if len(series) < 2:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    n = len(series)\n",
    "    total, pairs = 0.0, 0\n",
    "    for a in range(n):\n",
    "        for b in range(a+1, n):\n",
    "            d, _ = fastdtw(series[a], series[b], dist=euclidean)\n",
    "            total += d\n",
    "            pairs += 1\n",
    "    return float(total / max(pairs, 1))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Embedding & metrics\n",
    "# ============================================================\n",
    "\n",
    "def _evaluate_cluster_metrics(embeddings: np.ndarray, idxs: np.ndarray,\n",
    "                              location_labels: np.ndarray,\n",
    "                              location_entropy_base: Optional[int] = None) -> Dict[str, float]:\n",
    "    X = embeddings[idxs]\n",
    "    if X.shape[0] == 0:\n",
    "        return {'variance': 0.0, 'mean_sim': 1.0, 'entropy': 0.0, 'quality': 0.0, 'novelty': 0.0}\n",
    "    center = np.mean(X, axis=0, keepdims=True)\n",
    "    variance = float(np.mean(np.sum((X - center) ** 2, axis=1)))\n",
    "    if len(X) > 1:\n",
    "        cos_sim = cosine_similarity(X)\n",
    "        iu = np.triu_indices_from(cos_sim, k=1)\n",
    "        mean_sim = float(np.mean(cos_sim[iu])) if iu[0].size > 0 else 1.0\n",
    "    else:\n",
    "        mean_sim = 1.0\n",
    "    loc_counts = Counter(location_labels[idxs])\n",
    "    loc_probs = np.array(list(loc_counts.values()), dtype=np.float32)\n",
    "    loc_probs /= max(loc_probs.sum(), 1e-8)\n",
    "    base = int(location_entropy_base or len(set(location_labels)))\n",
    "    loc_entropy = float(entropy(loc_probs, base=base)) if base > 1 else 0.0\n",
    "    max_ent = np.log2(base) if base > 1 else 1.0\n",
    "    entropy_score = 1.0 - (loc_entropy / max_ent) if base > 1 else 1.0\n",
    "    quality = float((mean_sim / (variance + 1e-8)) * entropy_score)\n",
    "    novelty = float((loc_entropy / max_ent) * variance) if base > 1 else 0.0\n",
    "    return {'variance': variance, 'mean_sim': mean_sim,\n",
    "            'entropy': loc_entropy, 'quality': quality, 'novelty': novelty}\n",
    "\n",
    "\n",
    "def _load_supcon_encoder(checkpoint_path: str, device: torch.device) -> ConvSupConEncoder:\n",
    "    enc = ConvSupConEncoder().to(device)\n",
    "    sd = torch.load(checkpoint_path, map_location=device)\n",
    "    if isinstance(sd, dict) and \"state_dict\" in sd:\n",
    "        sd = sd[\"state_dict\"]\n",
    "    enc.load_state_dict(sd, strict=False)\n",
    "    enc.eval()\n",
    "    print(f\"[INFO] SupCon encoder loaded from {checkpoint_path} on {device}\")\n",
    "    return enc\n",
    "\n",
    "\n",
    "def _extract_embeds_from_dir(\n",
    "    dataset_path: str,\n",
    "    location_tag: str,\n",
    "    checkpoint_path: str,\n",
    "    *,\n",
    "    subset_fraction: float = 0.02,\n",
    "    subset_seed: int = 42,\n",
    "    batch_size: int = 256,\n",
    "    num_workers: int = 0\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    all_files = _list_audio_npy_files(dataset_path)\n",
    "    if len(all_files) == 0:\n",
    "        raise RuntimeError(f\"No .npy files found in {dataset_path}\")\n",
    "    n_sub = max(1, int(math.ceil(len(all_files) * subset_fraction)))\n",
    "    rng = np.random.RandomState(subset_seed)\n",
    "    chosen_idx = np.sort(rng.choice(len(all_files), size=n_sub, replace=False))\n",
    "    chosen_files = [all_files[i] for i in chosen_idx]\n",
    "\n",
    "    ds = SpectrogramDataset(dataset_path, os.path.join(dataset_path, \"labels.npy\"), augment_fn=None)\n",
    "    subset = Subset(ds, chosen_idx.tolist())\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    enc = _load_supcon_encoder(checkpoint_path, device)\n",
    "\n",
    "    loader = DataLoader(subset, batch_size=batch_size, shuffle=False,\n",
    "                        num_workers=num_workers, drop_last=False)\n",
    "\n",
    "    feats, cls_labels = [], []\n",
    "    t0 = time.perf_counter(); seen = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (x1, _, y) in enumerate(loader):\n",
    "            x1 = x1.to(device, non_blocking=True)\n",
    "            h = enc(x1).cpu().numpy().astype(\"float32\")\n",
    "            feats.append(h); cls_labels.append(y.numpy())\n",
    "            seen += x1.size(0)\n",
    "            if (step+1) % 10 == 0 or step == 0:\n",
    "                dt = time.perf_counter() - t0\n",
    "                print(f\"[Embed] {seen}/{n_sub} • {seen/max(dt,1e-9):.1f} it/s\")\n",
    "\n",
    "    H = np.vstack(feats).astype(\"float32\")\n",
    "    cls = np.concatenate(cls_labels, axis=0)\n",
    "    loc = np.array([location_tag] * H.shape[0], dtype=object)\n",
    "    print(f\"[INFO] {dataset_path} → {H.shape} embeds\")\n",
    "    return H, cls, loc, np.array(chosen_files, dtype=object)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Report generator\n",
    "# ============================================================\n",
    "\n",
    "def _carousel_html(cluster_id: int, scope: str, imgs: List[str]) -> str:\n",
    "    cid = f\"carousel_{scope}_{cluster_id}\"\n",
    "    indicators = \"\".join(\n",
    "        f'<button type=\"button\" data-bs-target=\"#{cid}\" data-bs-slide-to=\"{i}\" {\"class=active\" if i==0 else \"\"} aria-current=\"true\" aria-label=\"Slide {i+1}\"></button>'\n",
    "        for i in range(len(imgs))\n",
    "    )\n",
    "    items = \"\".join(\n",
    "        f'<div class=\"carousel-item {\"active\" if i==0 else \"\"}\"><div class=\"d-flex justify-content-center\">{img}</div></div>'\n",
    "        for i, img in enumerate(imgs)\n",
    "    )\n",
    "    return f\"\"\"\n",
    "    <div id=\"{cid}\" class=\"carousel slide\" data-bs-interval=\"false\" data-bs-touch=\"false\">\n",
    "      <div class=\"carousel-indicators\">{indicators}</div>\n",
    "      <div class=\"carousel-inner\">{items}</div>\n",
    "      <button class=\"carousel-control-prev\" type=\"button\" data-bs-target=\"#{cid}\" data-bs-slide=\"prev\">\n",
    "        <span class=\"carousel-control-prev-icon\" aria-hidden=\"true\"></span>\n",
    "        <span class=\"visually-hidden\">Previous</span>\n",
    "      </button>\n",
    "      <button class=\"carousel-control-next\" type=\"button\" data-bs-target=\"#{cid}\" data-bs-slide=\"next\">\n",
    "        <span class=\"carousel-control-next-icon\" aria-hidden=\"true\"></span>\n",
    "        <span class=\"visually-hidden\">Next</span>\n",
    "      </button>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def analyze_supcon_to_html(\n",
    "    checkpoint_path: str,\n",
    "    dataset_paths: List[str],\n",
    "    location_tags: List[str],\n",
    "    *,\n",
    "    cluster_method: str = \"kmeans\",   # 'kmeans' | 'gmm' | 'agglomerative'\n",
    "    n_clusters: int = 60,\n",
    "    subset_fraction: float = 0.02,\n",
    "    subset_seed: int = 42,\n",
    "    samples_per_cluster: int = 4,\n",
    "    top_n_clusters: Optional[int] = None   # rank by size; None = show all\n",
    ") -> str:\n",
    "    assert len(dataset_paths) == len(location_tags), \"dataset_paths and location_tags must match\"\n",
    "\n",
    "    # Collect embeddings from each location\n",
    "    embeds_all, class_all, loc_all, files_all = [], [], [], []\n",
    "    for path, tag in zip(dataset_paths, location_tags):\n",
    "        H, cls, loc, files = _extract_embeds_from_dir(\n",
    "            path, tag, checkpoint_path,\n",
    "            subset_fraction=subset_fraction, subset_seed=subset_seed\n",
    "        )\n",
    "        embeds_all.append(H); class_all.append(cls); loc_all.append(loc); files_all.append(files)\n",
    "\n",
    "    embeddings = np.vstack(embeds_all).astype(\"float32\")\n",
    "    class_labels = np.concatenate(class_all, axis=0).astype(object)\n",
    "    location_labels = np.concatenate(loc_all, axis=0).astype(object)\n",
    "    original_paths = np.concatenate(files_all, axis=0).astype(object)\n",
    "\n",
    "    # UMAP (cosine) on embeddings\n",
    "    print(f\"[INFO] UMAP on {embeddings.shape[0]}×{embeddings.shape[1]}\")\n",
    "    reducer = umap.UMAP(n_components=3, n_neighbors=15, min_dist=0.1,\n",
    "                        metric=\"cosine\", random_state=42)\n",
    "    proj_3d = reducer.fit_transform(embeddings)\n",
    "\n",
    "    # Clustering in embedding space\n",
    "    def _choose_clusterer(algorithm: str, X: np.ndarray, k: int):\n",
    "        if algorithm == \"kmeans\":\n",
    "            model = KMeans(n_clusters=k, n_init='auto', random_state=42).fit(X)\n",
    "            return model.labels_, None\n",
    "        elif algorithm == \"agglomerative\":\n",
    "            from sklearn.cluster import AgglomerativeClustering\n",
    "            model = AgglomerativeClustering(n_clusters=k).fit(X)\n",
    "            return model.labels_, None\n",
    "        elif algorithm == \"gmm\":\n",
    "            from sklearn.mixture import GaussianMixture\n",
    "            model = GaussianMixture(n_components=k, covariance_type='full', random_state=42).fit(X)\n",
    "            return model.predict(X), model.predict_proba(X)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported algorithm: {algorithm}\")\n",
    "\n",
    "    print(f\"[INFO] Clustering with {cluster_method} (k={n_clusters})\")\n",
    "    cluster_labels, _ = _choose_clusterer(cluster_method, embeddings, n_clusters)\n",
    "\n",
    "    # Global metrics (embedding space, not UMAP)\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    valid = (len(unique_clusters) > 1) and (embeddings.shape[0] > len(unique_clusters))\n",
    "\n",
    "    def _safe_metric(fn, X, y):\n",
    "        try:\n",
    "            return float(fn(X, y)) if valid else float(\"nan\")\n",
    "        except Exception:\n",
    "            return float(\"nan\")\n",
    "\n",
    "    sil = _safe_metric(silhouette_score, embeddings, cluster_labels)\n",
    "    dbi = _safe_metric(davies_bouldin_score, embeddings, cluster_labels)\n",
    "    ch  = _safe_metric(calinski_harabasz_score, embeddings, cluster_labels)\n",
    "\n",
    "    title_txt = f\"{cluster_method.capitalize()} (Sil={sil:.3f} | DBI={dbi:.3f} | CH={ch:.1f})\"\n",
    "    fig = px.scatter_3d(\n",
    "        x=proj_3d[:,0], y=proj_3d[:,1], z=proj_3d[:,2],\n",
    "        color=[str(c) for c in cluster_labels],\n",
    "        symbol=location_labels,\n",
    "        hover_data={\"Cluster\": cluster_labels, \"Class\": class_labels},\n",
    "        title=title_txt, opacity=0.85, height=800\n",
    "    )\n",
    "    umap_html = pio.to_html(fig, include_plotlyjs=\"cdn\", full_html=False)\n",
    "\n",
    "    # Per-cluster sections\n",
    "    base_for_entropy = len(set(location_labels))\n",
    "    cluster_ids = sorted(set(cluster_labels), key=lambda c: np.sum(cluster_labels==c), reverse=True)\n",
    "    if top_n_clusters is not None:\n",
    "        cluster_ids = cluster_ids[:int(top_n_clusters)]\n",
    "\n",
    "    # Accumulators for global spectrogram consistency summary\n",
    "    spec_cos_scores, spec_dtw_scores = [], []\n",
    "\n",
    "    blocks = []\n",
    "    for cid in cluster_ids:\n",
    "        idxs = np.where(cluster_labels == cid)[0]\n",
    "        if idxs.size == 0:\n",
    "            continue\n",
    "\n",
    "        sz = len(idxs)\n",
    "        loc_counts = Counter(location_labels[idxs])\n",
    "        cls_counts = Counter(class_labels[idxs])\n",
    "        metrics = _evaluate_cluster_metrics(embeddings, idxs, location_labels, location_entropy_base=base_for_entropy)\n",
    "\n",
    "        # New: spectrogram-space intra-cluster similarity\n",
    "        spec_cos = _avg_intra_cluster_spec_cosine(original_paths, idxs, fs=10000, max_samples=50)\n",
    "        spec_dtw = _avg_intra_cluster_spec_dtw(original_paths, idxs, fs=10000, max_samples=25)\n",
    "\n",
    "        if np.isfinite(spec_cos):\n",
    "            spec_cos_scores.append(spec_cos)\n",
    "        if np.isfinite(spec_dtw):\n",
    "            spec_dtw_scores.append(spec_dtw)\n",
    "\n",
    "        meta_html = \"<p><strong>Location Distribution:</strong></p><ul>\" + \"\".join(\n",
    "            f\"<li><b>{loc}</b>: {count} ({count/sz:.1%})</li>\" for loc, count in loc_counts.items()\n",
    "        ) + \"</ul>\"\n",
    "        meta_html += \"<p><strong>Class Distribution:</strong></p><ul>\" + \"\".join(\n",
    "            f\"<li>{cls}: {count}</li>\" for cls, count in cls_counts.items()\n",
    "        ) + \"</ul>\"\n",
    "        meta_html += f\"\"\"\n",
    "        <p><strong>Cluster Metrics (Embedding Space):</strong></p>\n",
    "        <ul>\n",
    "          <li>Size: {sz}</li>\n",
    "          <li>Intra-Cluster Variance: {metrics['variance']:.4f}</li>\n",
    "          <li>Mean Cosine Similarity (Embeddings): {metrics['mean_sim']:.4f}</li>\n",
    "          <li>Location Entropy: {metrics['entropy']:.3f}</li>\n",
    "          <li>Composite Quality Score: {metrics['quality']:.4f}</li>\n",
    "          <li><strong>Novelty Score:</strong> {metrics['novelty']:.4f}</li>\n",
    "        </ul>\n",
    "        <p><strong>Spectrogram Consistency (Signal Space):</strong></p>\n",
    "        <ul>\n",
    "          <li>Mean Spectrogram Cosine Similarity (↑ better): {spec_cos if np.isfinite(spec_cos) else float('nan'):.4f}</li>\n",
    "          <li>Mean Spectrogram DTW Distance (↓ better): {spec_dtw if np.isfinite(spec_dtw) else float('nan'):.2f}</li>\n",
    "        </ul>\n",
    "        \"\"\"\n",
    "\n",
    "        # nearest-to-center spectrogram exemplars\n",
    "        center = np.mean(embeddings[idxs], axis=0, keepdims=True)\n",
    "        dists = np.linalg.norm(embeddings[idxs] - center, axis=1)\n",
    "        order = np.argsort(dists)\n",
    "        pick = idxs[order[:min(samples_per_cluster, len(order))]]\n",
    "\n",
    "        thumbs = []\n",
    "        for i, p in enumerate(pick):\n",
    "            try:\n",
    "                arr = np.load(original_paths[p], mmap_mode=\"r\")\n",
    "                title = f\"#{i+1} | {location_labels[p]} | Class {class_labels[p]}\"\n",
    "                thumbs.append(_spec_img_base64(arr, title))\n",
    "            except Exception as e:\n",
    "                thumbs.append(f\"<p class='text-danger'>Error: {e}</p>\")\n",
    "\n",
    "        blocks.append(f\"<div class='col-md-6 mb-4'><h4>Cluster {cid}</h4>{meta_html}{_carousel_html(cid, 'supcon', thumbs)}</div>\")\n",
    "\n",
    "    cluster_html = \"\"\n",
    "    for i in range(0, len(blocks), 2):\n",
    "        cluster_html += \"<div class='row'>\" + \"\".join(blocks[i:i+2]) + \"</div>\"\n",
    "\n",
    "    # Global spectrogram-consistency summary\n",
    "    global_spec_cos = float(np.mean(spec_cos_scores)) if len(spec_cos_scores) else float(\"nan\")\n",
    "    global_spec_dtw = float(np.mean(spec_dtw_scores)) if len(spec_dtw_scores) else float(\"nan\")\n",
    "\n",
    "    summary_card = f\"\"\"\n",
    "    <div class='row mb-4'>\n",
    "      <div class='col-md-12'>\n",
    "        <div class='alert alert-info' role='alert'>\n",
    "          <h5 class='mb-2'>Spectrogram Consistency (Cluster Averages)</h5>\n",
    "          <ul class='mb-0'>\n",
    "            <li><strong>Mean Spectrogram Cosine Similarity</strong>: {global_spec_cos if np.isfinite(global_spec_cos) else float('nan'):.4f} (↑ better)</li>\n",
    "            <li><strong>Mean Spectrogram DTW Distance</strong>: {global_spec_dtw if np.isfinite(global_spec_dtw) else float('nan'):.2f} (↓ better)</li>\n",
    "          </ul>\n",
    "          <small>Note: Cosine computed on standardized spectrograms (z-norm, padded/cropped to a common shape). DTW is optional and subsampled for speed.</small>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    return f\"\"\"\n",
    "    <div class='section'>\n",
    "      <h2>{cluster_method.capitalize()} Clustering Analysis (SupCon • subset {int(subset_fraction*100)}%)</h2>\n",
    "      <div class=\"container\">\n",
    "        <div class=\"row justify-content-center mb-4\">\n",
    "          <div class=\"col-md-12 d-flex justify-content-center\">{umap_html}</div>\n",
    "        </div>\n",
    "        {summary_card}\n",
    "      </div>\n",
    "      {cluster_html}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def generate_supcon_full_report(\n",
    "    checkpoint_path: str,\n",
    "    dataset_paths: List[str],\n",
    "    location_tags: List[str],\n",
    "    *,\n",
    "    out_html: str = \"supcon_unsupervised_report.html\",\n",
    "    cluster_method: str = \"kmeans\",\n",
    "    n_clusters: int = 60,\n",
    "    subset_fraction: float = 0.02,\n",
    "    subset_seed: int = 42,\n",
    "    samples_per_cluster: int = 4,\n",
    "    top_n_clusters: Optional[int] = None,\n",
    ") -> str:\n",
    "    section = analyze_supcon_to_html(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        dataset_paths=list(dataset_paths),\n",
    "        location_tags=list(location_tags),\n",
    "        cluster_method=cluster_method,\n",
    "        n_clusters=int(n_clusters),\n",
    "        subset_fraction=subset_fraction,\n",
    "        subset_seed=subset_seed,\n",
    "        samples_per_cluster=samples_per_cluster,\n",
    "        top_n_clusters=top_n_clusters,\n",
    "    )\n",
    "    html = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Unsupervised Clustering Report (SupCon)</title>\n",
    "        <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"></script>\n",
    "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; padding: 20px; background-color: #f5f5f5; }}\n",
    "            h1 {{ color: #2c3e50; }}\n",
    "            h2, h4 {{ color: #34495e; }}\n",
    "            hr {{ border-top: 2px solid #bbb; margin-top: 40px; margin-bottom: 40px; }}\n",
    "            .section {{ margin-bottom: 60px; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "      <h1 class='mb-4'>Unsupervised Latent Clustering Report (SupCon)</h1>\n",
    "      <p><strong>Locations:</strong> {', '.join(location_tags)}</p>\n",
    "      <p><strong>Subset:</strong> {int(subset_fraction*100)}% • Seed: {subset_seed}</p>\n",
    "      <p><strong>Clusterer:</strong> {cluster_method} • <strong>k</strong> = {n_clusters}</p>\n",
    "      <hr>\n",
    "      {section}\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    with open(out_html, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(f\"✅ Report saved to: {out_html}\")\n",
    "    return out_html\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CLI\n",
    "# ============================================================\n",
    "\n",
    "out_path = generate_supcon_full_report(\n",
    "    checkpoint_path=\"best_encoder_pretrain.pth\",\n",
    "    dataset_paths=[\"/notebooks/dataset_preprocessed\"],  # list\n",
    "    location_tags=[\"PR_U1137\"],                         # same length as dataset_paths\n",
    "    cluster_method=\"kmeans\",                            # or \"gmm\", \"agglomerative\"\n",
    "    n_clusters=60,\n",
    "    out_html=\"SupCon_unsupervised_clustering_report.html\",\n",
    "    subset_fraction=0.2,\n",
    "    subset_seed=42,\n",
    "    samples_per_cluster=4,   # optional (default 4)\n",
    "    top_n_clusters=40,       # optional: show only top-N clusters; remove to show all\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
